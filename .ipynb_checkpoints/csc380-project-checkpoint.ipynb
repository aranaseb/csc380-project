{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585e9ddf-3acb-4fbe-99b7-80a53ea0a4b2",
   "metadata": {},
   "source": [
    "# CSC380 Decision Tree Classifier Project\n",
    "\n",
    "<div>\n",
    "        Members: Sebastian Arana and Austin Baber\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810f4445-8bc6-4759-a99c-7cd552bc6f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87abda0-2639-40b1-8cb8-3ab5189718c3",
   "metadata": {},
   "source": [
    "### Imports and globals\n",
    "<div>We are using scikit-learn, numpy, pandas, matplotlib</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a60da78-f715-4851-97a3-087a601db4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "MIN_SUPPORT = 10 # per spec\n",
    "MAX_TREE_HEIGHT = None # computed dynamically\n",
    "\n",
    "def set_max_tree_height(num_classes):\n",
    "    \"\"\"set MAX_TREE_HEIGHT based on number of classes\"\"\"\n",
    "    global MAX_TREE_HEIGHT\n",
    "    MAX_TREE_HEIGHT = math.ceil(math.log2(num_classes)) + 1\n",
    "    print(f\"MAX_TREE_HEIGHT set to {MAX_TREE_HEIGHT} for m = {num_classes} classes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33815ce8-36b6-40e6-bde5-ee69b1cda147",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "<div>Parse train/ test data</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0768fd1b-dacc-43b1-8905-4cfb5442d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, label = \"Class\"):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # skip stray index columns\n",
    "    df = df.loc[:, ~df.columns.str.lower().str.startswith(\"unnamed\")] # bitwise NOT\n",
    "\n",
    "    y = pd.to_numeric(df[label], errors=\"raise\").astype(int).to_numpy()\n",
    "    X = df.drop(columns=[label]).astype(float).to_numpy()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8635d44-583c-4e17-a816-893a749893dc",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "<div>Find best split using gini score (logic based on predictive lecture 2 slides)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d074245a-a37c-4210-87dd-892d4b39824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(y):\n",
    "    \"\"\"compute impurity for labels y\"\"\"\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    _, counts = np.unique(y, return_counts = True)\n",
    "    p = counts / counts.sum()\n",
    "    return 1 - np.sum(p**2)\n",
    "\n",
    "def gini_score(y_left, y_right):\n",
    "    \"\"\"weighted impurity of a split\"\"\"\n",
    "    n = len(y_left) + len(y_right)\n",
    "    return (len(y_left)/n) * gini_impurity(y_left) + (len(y_right)/n) * gini_impurity(y_right)\n",
    "\n",
    "def combinations(classes):\n",
    "    \"\"\"returns all r = 1 and r = 2 combinations, up to m = 9\"\"\"\n",
    "    \"\"\"copy/pasted from previous hw assignment\"\"\"\n",
    "    m = len(classes)\n",
    "    combination_list = []\n",
    "    for i in classes: # r = 1\n",
    "        combination_list.append((i,))\n",
    "    for i in range(m): # r = 2\n",
    "        for j in range(i + 1, m):\n",
    "            combination_list.append((classes[i], classes[j]))\n",
    "    return combination_list    \n",
    "\n",
    "def best_split(X, y, linear = True):\n",
    "    \"\"\"\n",
    "    try all groupings, fit an SVM, and pick the best split by gini score\n",
    "    Returns: best_clf, left_idx, right_idx\n",
    "    \"\"\"\n",
    "    classes = list(np.unique(y))\n",
    "    combination_list = combinations(classes)\n",
    "\n",
    "    best_gini = 1.0\n",
    "    best_clf = None\n",
    "    best_left_idx, best_right_idx = None, None\n",
    "\n",
    "    for group in combination_list:\n",
    "        # binary labels: 1 if in group, else 0\n",
    "        y_binary = np.isin(y, group).astype(int)\n",
    "\n",
    "        # skip if all same label\n",
    "        if len(np.unique(y_binary)) < 2:\n",
    "            continue\n",
    "\n",
    "        # train SVM\n",
    "        kernel = 'linear' if linear else 'rbf'\n",
    "        clf = SVC(kernel = kernel)\n",
    "        clf.fit(X, y_binary)\n",
    "\n",
    "        # split data based on decision function\n",
    "        decision_vals = clf.decision_function(X)\n",
    "        left_idx = decision_vals >= 0\n",
    "        right_idx = ~left_idx # bitwise NOT\n",
    "\n",
    "        # compute gini\n",
    "        gini = gini_score(y[left_idx], y[right_idx])\n",
    "\n",
    "        # we want lower gini\n",
    "        if gini < best_gini:\n",
    "            best_gini = gini\n",
    "            best_clf = clf\n",
    "            best_left_idx = left_idx\n",
    "            best_right_idx = right_idx\n",
    "\n",
    "    return best_clf, best_left_idx, best_right_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82656a28-498f-467c-a335-9306da75018e",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "<div>Build tree</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ecd53d-8312-443a-9cbd-cd73bcffef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.is_leaf = False\n",
    "        self.label = None\n",
    "        self.clf = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "def build_tree(X, y, depth = 0, max_depth = None, min = 10, linear = True):\n",
    "    node = Node()\n",
    "\n",
    "    # base case\n",
    "    if depth >= MAX_TREE_HEIGHT or len(np.unique(y)) == 1 or len(y) < MIN_SUPPORT:\n",
    "        node.is_leaf = True\n",
    "        node.label = np.bincount(y).argmax()\n",
    "        return node\n",
    "\n",
    "    # find best split\n",
    "    clf, left_idx, right_idx = best_split(X, y, linear = linear)\n",
    "\n",
    "    # if none, make leaf\n",
    "    if clf is None:\n",
    "        node.is_leaf = True\n",
    "        node.label = np.bincount(y).argmax()\n",
    "        return node\n",
    "\n",
    "    node.clf = clf\n",
    "    node.left = build_tree(X[left_idx], y[left_idx], depth+1, MAX_TREE_HEIGHT, MIN_SUPPORT, linear)\n",
    "    node.right = build_tree(X[right_idx], y[right_idx], depth+1, MAX_TREE_HEIGHT, MIN_SUPPORT, linear)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2854c493-b2b6-470b-b439-87eeff51c201",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "<div>Make predictions</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6891a1-0dce-4df4-a043-fcb959a7f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict1(node, x):\n",
    "    \"\"\"traverse tree to predict label for a sample\"\"\"\n",
    "    if node.is_leaf:\n",
    "        return node.label\n",
    "    decision_val = node.clf.decision_function([x])[0]\n",
    "    if decision_val >= 0:\n",
    "        return predict1(node.left, x)\n",
    "    else:\n",
    "        return predict1(node.right, x)\n",
    "\n",
    "def predict(node, X):\n",
    "    return np.array([predict1(node, x) for x in X])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ddf8b9-36a9-4ae0-ade6-1067db9d56b7",
   "metadata": {},
   "source": [
    "### Wrapper for modularization per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb1325fe-bcf5-42f0-a647-602274611ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(train_csv, test_csv, linear = True):\n",
    "    X_train, y_train = load_dataset(train_csv)\n",
    "    X_test, y_test = load_dataset(test_csv)\n",
    "\n",
    "    # update tree height for this dataset\n",
    "    set_max_tree_height(len(np.unique(y_train)))\n",
    "\n",
    "    #m = len(np.unique(y_train))\n",
    "    #max_depth = math.ceil(math.log2(m)) + 1\n",
    "\n",
    "    tree = build_tree(X_train, y_train, MAX_TREE_HEIGHT, MIN_SUPPORT, linear = linear)\n",
    "    y_pred = predict(tree, X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return tree, acc, MAX_TREE_HEIGHT, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be02b6-ef99-460c-88bd-8086a04ef179",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604e87cf-9af1-4cae-b278-0711ea753bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_TREE_HEIGHT set to 3 for m = 4 classes.\n",
      "Data1 accuracy:  0.3246753246753247\n",
      "[[ 0  0  0 15]\n",
      " [ 0  0  0 17]\n",
      " [ 0  0  0 20]\n",
      " [ 0  0  0 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.00      0.00      0.00        17\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.32      1.00      0.49        25\n",
      "\n",
      "    accuracy                           0.32        77\n",
      "   macro avg       0.08      0.25      0.12        77\n",
      "weighted avg       0.11      0.32      0.16        77\n",
      "\n",
      "===========================================================\n",
      "MAX_TREE_HEIGHT set to 3 for m = 4 classes.\n",
      "Data2 accuracy:  0.24\n",
      "[[24  0  0  0]\n",
      " [26  0  0  0]\n",
      " [21  0  0  0]\n",
      " [29  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      1.00      0.39        24\n",
      "           2       0.00      0.00      0.00        26\n",
      "           3       0.00      0.00      0.00        21\n",
      "           4       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.24       100\n",
      "   macro avg       0.06      0.25      0.10       100\n",
      "weighted avg       0.06      0.24      0.09       100\n",
      "\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "# data 1–3: (linear)\n",
    "tree1, acc1, depth1, X1_test, y1_test = train_and_eval(\"data/data1/Data1Train.csv\", \"data/data1/Data1Test.csv\", linear = True)\n",
    "\n",
    "print(\"Data1 accuracy: \", acc1)\n",
    "print(confusion_matrix(y1_test, predict(tree1, X1_test)))\n",
    "print(classification_report(y1_test, predict(tree1, X1_test), zero_division = 0))\n",
    "print(\"===========================================================\")\n",
    "\n",
    "tree2, acc2, depth2, X2_test, y2_test = train_and_eval(\"data/data2/Data2Train.csv\", \"data/data2/Data2Test.csv\", linear = True)\n",
    "\n",
    "print(\"Data2 accuracy: \", acc2)\n",
    "print(confusion_matrix(y2_test, predict(tree2, X2_test)))\n",
    "print(classification_report(y2_test, predict(tree2, X2_test), zero_division = 0))\n",
    "print(\"===========================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
