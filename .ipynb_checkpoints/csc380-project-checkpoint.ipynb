{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4e3663-9494-4c9d-8a10-2f96b436549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e9ddf-3acb-4fbe-99b7-80a53ea0a4b2",
   "metadata": {},
   "source": [
    "# CSC380 Decision Tree Classifier Project\n",
    "\n",
    "<div>\n",
    "        Members: Sebastian Arana and Austin Baber\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810f4445-8bc6-4759-a99c-7cd552bc6f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87abda0-2639-40b1-8cb8-3ab5189718c3",
   "metadata": {},
   "source": [
    "### Imports and globals\n",
    "<div>We are using scikit-learn, numpy, pandas, matplotlib</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a60da78-f715-4851-97a3-087a601db4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "MIN_SUPPORT = 10 # per spec\n",
    "MAX_TREE_HEIGHT = None # computed dynamically\n",
    "\n",
    "def set_max_tree_height(num_classes):\n",
    "    \"\"\"set MAX_TREE_HEIGHT based on number of classes\"\"\"\n",
    "    global MAX_TREE_HEIGHT\n",
    "    MAX_TREE_HEIGHT = math.ceil(math.log2(num_classes)) + 1\n",
    "    print(f\"MAX_TREE_HEIGHT set to {MAX_TREE_HEIGHT} for m = {num_classes} classes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33815ce8-36b6-40e6-bde5-ee69b1cda147",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "<div>Parse train/ test data</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0768fd1b-dacc-43b1-8905-4cfb5442d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, label = \"Class\"):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # skip stray index columns\n",
    "    df = df.loc[:, ~df.columns.str.lower().str.startswith(\"unnamed\")] # bitwise NOT\n",
    "\n",
    "    y = pd.to_numeric(df[label], errors=\"raise\").astype(int).to_numpy()\n",
    "    X = df.drop(columns=[label]).astype(float).to_numpy()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8635d44-583c-4e17-a816-893a749893dc",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "<div>Find best split using gini score (logic based on predictive lecture 2 slides)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d074245a-a37c-4210-87dd-892d4b39824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(y):\n",
    "    \"\"\"compute impurity for labels y\"\"\"\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    _, counts = np.unique(y, return_counts = True)\n",
    "    p = counts / counts.sum()\n",
    "    return 1 - np.sum(p**2)\n",
    "\n",
    "def gini_score(y_left, y_right):\n",
    "    \"\"\"weighted impurity of a split\"\"\"\n",
    "    n = len(y_left) + len(y_right)\n",
    "    if n == 0:\n",
    "        return np.inf\n",
    "    return (len(y_left)/n) * gini_impurity(y_left) + (len(y_right)/n) * gini_impurity(y_right)\n",
    "\n",
    "def combinations(classes):\n",
    "    \"\"\"returns all r = 1 and r = 2 combinations, up to m = 9\"\"\"\n",
    "    \"\"\"copy/pasted from previous hw assignment\"\"\"\n",
    "    m = len(classes)\n",
    "    combination_list = []\n",
    "    for i in classes: # r = 1\n",
    "        combination_list.append((i,))\n",
    "    for i in range(m): # r = 2\n",
    "        for j in range(i + 1, m):\n",
    "            combination_list.append((classes[i], classes[j]))\n",
    "    return combination_list    \n",
    "\n",
    "def best_split(X, y, linear = True):\n",
    "    \"\"\"\n",
    "    try all groupings, fit an SVM, and pick the best split by gini score\n",
    "    Returns: best_clf, left_idx, right_idx\n",
    "    \"\"\"\n",
    "    classes = list(np.unique(y))\n",
    "    combination_list = combinations(classes)\n",
    "\n",
    "    best_gini = np.inf\n",
    "    best_clf = None\n",
    "    best_left_idx, best_right_idx = None, None\n",
    "\n",
    "    for group in combination_list:\n",
    "        # binary labels: 1 if in group, else 0\n",
    "        y_binary = np.where(np.isin(y, group), 1, -1)\n",
    "        # skip if all same label\n",
    "        if len(np.unique(y_binary)) < 2:\n",
    "            continue\n",
    "\n",
    "        # train SVM\n",
    "        kernel = 'linear' if linear else 'rbf'\n",
    "        clf = SVC(kernel = kernel, C=1)\n",
    "        clf.fit(X, y_binary)\n",
    "\n",
    "        # split data based on decision function\n",
    "        decision_vals = clf.decision_function(X)\n",
    "        left_idx = decision_vals >= 0\n",
    "        right_idx = ~left_idx # bitwise NOT\n",
    "        if left_idx.sum() == 0 or right_idx.sum() == 0: # get out\n",
    "            continue\n",
    "\n",
    "        # compute gini\n",
    "        gini = gini_score(y[left_idx], y[right_idx])\n",
    "\n",
    "        # we want lower gini\n",
    "        if gini < best_gini:\n",
    "            best_gini = gini\n",
    "            best_clf = clf\n",
    "            best_left_idx = left_idx\n",
    "            best_right_idx = right_idx\n",
    "\n",
    "    return best_clf, best_left_idx, best_right_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82656a28-498f-467c-a335-9306da75018e",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "<div>Build tree</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ecd53d-8312-443a-9cbd-cd73bcffef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.is_leaf = False\n",
    "        self.label = None\n",
    "        self.clf = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "def build_tree(X, y, depth = 0, max_depth = 3, min_support = 10, linear = True):\n",
    "    node = Node()\n",
    "\n",
    "    # base case\n",
    "    if depth >= max_depth or len(np.unique(y)) == 1 or len(y) < min_support:\n",
    "        node.is_leaf = True\n",
    "        node.label = np.bincount(y).argmax()\n",
    "        return node\n",
    "\n",
    "    # find best split\n",
    "    clf, left_idx, right_idx = best_split(X, y, linear=linear)\n",
    "\n",
    "    # if none, make leaf\n",
    "    if clf is None:\n",
    "        node.is_leaf = True\n",
    "        node.label = int(np.bincount(y).argmax())\n",
    "        return node\n",
    "    node.clf = clf\n",
    "    node.left  = build_tree(X[left_idx],  y[left_idx],  depth+1, max_depth, min_support, linear)\n",
    "    node.right = build_tree(X[right_idx], y[right_idx], depth+1, max_depth, min_support, linear)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2854c493-b2b6-470b-b439-87eeff51c201",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "<div>Make predictions</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c6891a1-0dce-4df4-a043-fcb959a7f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict1(node, x):\n",
    "    \"\"\"traverse tree to predict label for a sample\"\"\"\n",
    "    if node.is_leaf:\n",
    "        return node.label\n",
    "    decision_val = node.clf.decision_function([x])[0]\n",
    "    if decision_val >= 0:\n",
    "        return predict1(node.left, x)\n",
    "    else:\n",
    "        return predict1(node.right, x)\n",
    "\n",
    "def predict(node, X):\n",
    "    return np.array([predict1(node, x) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ddf8b9-36a9-4ae0-ade6-1067db9d56b7",
   "metadata": {},
   "source": [
    "### Wrapper for modularization per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb1325fe-bcf5-42f0-a647-602274611ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(train_csv, test_csv, linear = True):\n",
    "    X_train, y_train = load_dataset(train_csv)\n",
    "    X_test, y_test = load_dataset(test_csv)\n",
    "\n",
    "    # update tree height for this dataset\n",
    "    set_max_tree_height(len(np.unique(y_train)))\n",
    "\n",
    "    #m = len(np.unique(y_train))\n",
    "    #max_depth = math.ceil(math.log2(m)) + 1\n",
    "\n",
    "    clf, left_idx, right_idx = best_split(X_train, y_train, linear=linear)\n",
    "\n",
    "    tree = build_tree(X_train, y_train, MAX_TREE_HEIGHT, MIN_SUPPORT, linear = linear)\n",
    "    y_pred = predict(tree, X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return tree, acc, MAX_TREE_HEIGHT, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b192126-fed5-48d5-ab11-148700b03615",
   "metadata": {},
   "source": [
    "### Interactive Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9459406-6844-4514-b9a4-9e97f27c387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_plot(tree, X, y):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Plot training data\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolor='k', s=50)\n",
    "    plt.title(\"Click to predict with Decision Tree (SVM splits)\")\n",
    "\n",
    "    draw_bounds(tree)\n",
    "    \n",
    "    # Set axis limits\n",
    "    ax.set_xlim([X[:, 0].min() - 1, X[:, 0].max() + 1])\n",
    "    ax.set_ylim([X[:, 1].min() - 1, X[:, 1].max() + 1])\n",
    "    \n",
    "    # Click handler\n",
    "    def onclick(event):\n",
    "        if event.inaxes is not None:\n",
    "            tx = 'xdata=%f, ydata=%f' % (event.xdata, event.ydata)\n",
    "            if (-clf.intercept_-clf.coef_[0,0]*event.xdata)/clf.coef_[0,1]<event.ydata:\n",
    "                tx = tx + ' Class 1 is selected'\n",
    "            else:\n",
    "                tx = tx + ' Class 2 is selected'\n",
    "            plt.cla()\n",
    "            plt.scatter(X[:, 0], X[:, 1], marker='o', c=y)\n",
    "            plt.plot([minX0D,maxX0D],[minX1,maxX1])\n",
    "            ax.set_xlim([minX0D, maxX0D])\n",
    "            ax.set_ylim([minX1D, maxX1D])\n",
    "            ax.scatter([event.xdata],[event.ydata],c='r')\n",
    "                \n",
    "            text.set_text(tx)\n",
    "            fig.canvas.draw()\n",
    "        else:\n",
    "            print('Clicked outside of an axis.')\n",
    "    \n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    plt.show()\n",
    "\n",
    "def draw_bounds(node):\n",
    "    if not node or node.is_leaf:\n",
    "        return\n",
    "\n",
    "    clf = node.clf\n",
    "    \n",
    "    # Plot boundaries\n",
    "    minX0D = np.min(X[:, 0])\n",
    "    maxX0D = np.max(X[:, 0])\n",
    "    minX1D = np.min(X[:, 1])\n",
    "    maxX1D = np.max(X[:, 1])\n",
    "    minX1 = (-clf.intercept_-clf.coef_[0,0]*minX0D)/clf.coef_[0,1]\n",
    "    maxX1 = (-clf.intercept_-clf.coef_[0,0]*maxX0D)/clf.coef_[0,1]\n",
    "\n",
    "    # Plot lines\n",
    "    plt.plot([minX0D,maxX0D],[minX1,maxX1])\n",
    "    ax.set_xlim([minX0D, maxX0D])\n",
    "    ax.set_ylim([minX1D, maxX1D])\n",
    "\n",
    "    draw_bounds(node.left)\n",
    "    draw_bounds(node.right)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be02b6-ef99-460c-88bd-8086a04ef179",
   "metadata": {},
   "source": [
    "## Train and Test Models\n",
    "<p>Now we run our models on each set of training and test data. What will be printed:</p>\n",
    "<ul>\n",
    "    <li>Max tree height for this dataset's number of classes</li>\n",
    "    <li>Accuracy of our model on the test set</li>\n",
    "    <li>SciKit's classification report</li>        \n",
    "    <li>Our interactive plot of the data and boundaries</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f03e1-7dac-4790-8542-91b0e607fc28",
   "metadata": {},
   "source": [
    "### Dataset 1: Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "604e87cf-9af1-4cae-b278-0711ea753bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_TREE_HEIGHT set to 3 for m = 4 classes.\n",
      "Data1 accuracy:  1.0\n",
      "[[15  0  0  0]\n",
      " [ 0 17  0  0]\n",
      " [ 0  0 20  0]\n",
      " [ 0  0  0 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00        17\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        77\n",
      "   macro avg       1.00      1.00      1.00        77\n",
      "weighted avg       1.00      1.00      1.00        77\n",
      "\n",
      "===========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data 1–3: (linear)\n",
    "tree1, acc1, depth1, X1_test, y1_test = train_and_eval(\"data/data1/Data1Train.csv\", \"data/data1/Data1Test.csv\", linear = True)\n",
    "\n",
    "print(\"Data1 accuracy: \", acc1)\n",
    "print(confusion_matrix(y1_test, predict(tree1, X1_test)))\n",
    "print(classification_report(y1_test, predict(tree1, X1_test), zero_division = 0))\n",
    "print(\"===========================================================\\n\")\n",
    "\n",
    "#interactive_plot(tree1, X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed77d7-6b39-4efd-ade4-535abdd9b2d5",
   "metadata": {},
   "source": [
    "### Dataset 2: Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c6c249d-4656-42d5-8a56-653467576b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_TREE_HEIGHT set to 3 for m = 4 classes.\n",
      "Data2 accuracy:  1.0\n",
      "[[24  0  0  0]\n",
      " [ 0 26  0  0]\n",
      " [ 0  0 21  0]\n",
      " [ 0  0  0 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        24\n",
      "           2       1.00      1.00      1.00        26\n",
      "           3       1.00      1.00      1.00        21\n",
      "           4       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "===========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree2, acc2, depth2, X2_test, y2_test = train_and_eval(\"data/data2/Data2Train.csv\", \"data/data2/Data2Test.csv\", linear = True)\n",
    "\n",
    "print(\"Data2 accuracy: \", acc2)\n",
    "print(confusion_matrix(y2_test, predict(tree2, X2_test)))\n",
    "print(classification_report(y2_test, predict(tree2, X2_test), zero_division = 0))\n",
    "print(\"===========================================================\\n\")\n",
    "\n",
    "#interactive_plot(tree2, X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa275fa-ea89-4045-927c-bde00c8094b6",
   "metadata": {},
   "source": [
    "### Dataset 3: Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def08a84-f152-41f0-a0ac-76ec2a207b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_TREE_HEIGHT set to 3 for m = 3 classes.\n",
      "Data3 accuracy:  0.95\n",
      "[[19  1  0]\n",
      " [ 0 19  1]\n",
      " [ 1  0 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.95      0.95        20\n",
      "           2       0.95      0.95      0.95        20\n",
      "           3       0.95      0.95      0.95        20\n",
      "\n",
      "    accuracy                           0.95        60\n",
      "   macro avg       0.95      0.95      0.95        60\n",
      "weighted avg       0.95      0.95      0.95        60\n",
      "\n",
      "===========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree3, acc3, depth3, X3_test, y3_test = train_and_eval(\"data/data3/Data3Train.csv\", \"data/data3/Data3Test.csv\", linear = True)\n",
    "\n",
    "print(\"Data3 accuracy: \", acc3)\n",
    "print(confusion_matrix(y3_test, predict(tree3, X3_test)))\n",
    "print(classification_report(y3_test, predict(tree3, X3_test), zero_division = 0))\n",
    "print(\"===========================================================\\n\")\n",
    "\n",
    "#interactive_plot(tree3, X3_test, y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b785e-fa55-4104-8917-8dc990d0ef23",
   "metadata": {},
   "source": [
    "### Dataset 4: Nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b880343-5100-4793-8fe8-20132d4bf05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_TREE_HEIGHT set to 3 for m = 4 classes.\n",
      "Data4 accuracy:  1.0\n",
      "[[15  0  0  0]\n",
      " [ 0 33  0  0]\n",
      " [ 0  0 24  0]\n",
      " [ 0  0  0 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        24\n",
      "           4       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           1.00        96\n",
      "   macro avg       1.00      1.00      1.00        96\n",
      "weighted avg       1.00      1.00      1.00        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree4, acc4, depth4, X4_test, y4_test = train_and_eval(\"data/data4/Data4Train.csv\", \"data/data4/Data4Test.csv\", linear = False)\n",
    "\n",
    "print(\"Data4 accuracy: \", acc4)\n",
    "print(confusion_matrix(y4_test, predict(tree4, X4_test)))\n",
    "print(classification_report(y4_test, predict(tree4, X4_test), zero_division = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
